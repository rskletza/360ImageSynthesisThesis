\vspace*{2cm}

\begin{center}
    \textbf{Abstract}
\end{center}

\vspace*{1cm}

\noindent 
Virtual Reality technology allows users to experience virtual environments by interacting with, and navigating within them. These environments tend to be either meticulously modeled in 3D by hand, or prerecorded using 360\degree cameras. The advantage of using 360\degree images is that they achieve a high level of realism with little effort, however, they often limit the user to a single viewpoint.
Image-based rendering, or image-based synthesis aims to create new viewpoints based on captured viewpoints, in the best case enabling a user to navigate freely around a scene captured with 360\degree cameras.
This thesis proposes a pixel-based 2~DoF synthesis technique that combines basic reprojection using proxy geometry with flow-based interpolation.
A proof-of-concept implementation of the approach is presented, which leverages 1~DoF interpolation using optical flow to improve the 
The possible parameter space is explored a select set of parameters are
tested using a set of different virtual and real scenes.
The results are then evaluated based on mathematical error metrics, as well as visible artefacts. The results of the evaluation show that the flow-based method improves the basic method in a number of cases.

